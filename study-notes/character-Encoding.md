# 字符编码

我们已经讲过了，字符串也是一种数据类型，但是，字符串比较特殊的是还有一个编码问题。

因为计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是255（二进制11111111=十进制255），如果要表示更大的整数，就必须用更多的字节。比如两个字节可以表示的最大整数是`65535`，4个字节可以表示的最大整数是`4294967295`。

由于计算机是美国人发明的，因此，最早只有127个字符被编码到计算机里，也就是大小写英文字母、数字和一些符号，这个编码表被称为`ASCII`编码，比如大写字母`A`的编码是`65`，小写字母`z`的编码是`122`。

但是要处理中文显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了`GB2312`编码，用来把中文编进去。

你可以想得到的是，全世界有上百种语言，日本把日文编到`Shift_JIS`里，韩国把韩文编到`Euc-kr`里，各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码。

![char-encoding-problem](https://cdn.liaoxuefeng.com/cdn/files/attachments/0013872491802084161ec9ef7d143a897e1584819535656000/0)

因此，Unicode应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。

Unicode标准也在不断发展，但最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要4个字节）。现代操作系统和大多数编程语言都直接支持Unicode。

现在，捋一捋ASCII编码和Unicode编码的区别：ASCII编码是1个字节，而Unicode编码通常是2个字节。

字母`A`用ASCII编码是十进制的`65`，二进制的`01000001`；

字符`0`用ASCII编码是十进制的`48`，二进制的`00110000`，注意字符`'0'`和整数`0`是不同的；

汉字`中`已经超出了ASCII编码的范围，用Unicode编码是十进制的`20013`，二进制的`01001110 00101101`。

你可以猜测，如果把ASCII编码的`A`用Unicode编码，只需要在前面补0就可以，因此，`A`的Unicode编码是`00000000 01000001`。

新的问题又出现了：如果统一成Unicode编码，乱码问题从此消失了。但是，如果你写的文本基本上全部是英文的话，用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算。

所以，本着节约的精神，又出现了把Unicode编码转化为“可变长编码”的`UTF-8`编码。UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间：

| 字符   | ASCII    | Unicode           | UTF-8                      |
| ---- | -------- | ----------------- | -------------------------- |
| A    | 01000001 | 00000000 01000001 | 01000001                   |
| 中    | x        | 01001110 00101101 | 11100100 10111000 10101101 |

从上面的表格还可以发现，UTF-8编码有一个额外的好处，就是ASCII编码实际上可以被看成是UTF-8编码的一部分，所以，大量只支持ASCII编码的历史遗留软件可以在UTF-8编码下继续工作。

搞清楚了ASCII、Unicode和UTF-8的关系，我们就可以总结一下现在计算机系统通用的字符编码工作方式：

在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。

用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件：

![rw-file-utf-8](https://cdn.liaoxuefeng.com/cdn/files/attachments/001387245992536e2ba28125cf04f5c8985dbc94a02245e000/0)

浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器：

![web-utf-8](https://cdn.liaoxuefeng.com/cdn/files/attachments/001387245979827634fd6204f9346a1ae6358d9ed051666000/0)

所以你看到很多网页的源码上会有类似`<meta charset="UTF-8" />`的信息，表示该网页正是用的UTF-8编码。

# 问题

"计算机内存中，统一使用Unicode编码，需要保存或者传输时，转换成UTF8编码。"，既然这样为什么不直接用UTF-8呢，而非要进行一次转换？

Unicode的字符码，很少在计算机中直接用在存储和表达文本上。原因无他：太浪费空间了。Unicode字符码是32位，4个字节。平常使用的字符里，99%以上的字符都不会突破2个字节。

为了节省空间，人们就对Unicode的字符码再做二次编码，这就诞生了UTF-8，UTF-16，UTF-32等编码标准。除了UTF-32，UTF-8和UTF-16都是不定长的编码，他们的意思是按照编码规则，将一个Unicode字符的字符码，编码成N个8位或者N个16位。至于N是几，要看具体的字符来定。UTF-32例外的原因是，他已经足够直接保存Unicode的字符码了……

LE是“小端”的缩写。因为只要是多字节的数据，就有端序问题，也就是高位字节在先还是低位字节在先的问题。windows平台默认小端，即低位字节在先。

Windows身上的“历史原因”，在于Unicode标准初生的时候，字符码其实是16位，那个时候的UTF-16就能直接保存Unicode字符码。于是Windows就直接将自己使用的UTF-16 LE编码命名为“Unicode"，这在当时是名符其实的。但是后来西方人尴尬地发现如果把中国人故纸堆里的罕用字，各种小语种的文字都收进去的话，16位65536个码位仍然是不够用的。Unicode升级成了32位，出现了字符码突破16位的字符，UTF-16从定长码变成了不定长码，对于Windows来说，这就很坑爹了。尽管字符码在16位以内的字符，UTF-16编码仍然保持不变，但还是很坑爹。

***在保存和传输文本的时候，用UTF-8很多，是因为对于大量以拉丁字母等ANSI字符为主的文献，UTF-8非常节省空间。但计算机处理文本的时候，内存中一般都不用UTF-8。因为UTF-8是变长编码，不从头扫描一遍，你不知道第几个字符在哪个位置上，这在处理的时候非常浪费时间。***现在很多语言/程序的处理办法，是使用源于原始UTF-16的一个定长编码，只处理字符码在16位以内的字符，不支持超过16位的罕见字。这种16位定长的编码方式被称为UCS-2。那些零星的几个突破16位的字符，除非你专门研究古文或者奇怪的小语种，一般来说是遇不到的。遇到了也是黑人问号脸。



